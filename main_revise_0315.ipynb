{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_index\n",
    "llama_index.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Query Engine & Retrievers\n",
    "from engine import local_llm_model\n",
    "from engine import load_db\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import QueryFusionRetriever\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index import set_global_service_context\n",
    "\n",
    "# Node Postprocessors\n",
    "from llama_index.postprocessor import (\n",
    "    SentenceTransformerRerank,\n",
    "    LongContextReorder,\n",
    "    # KeywordNodePostprocessor,\n",
    "    LLMRerank\n",
    ")\n",
    "from postprocess import (\n",
    "    DuplecatedNodePostprocessor,\n",
    "    UnionNodePostprocessor,\n",
    "    LimitRetrievedNodesLength, \n",
    "    UnionNodePostprocessorSortedScore\n",
    ")\n",
    "\n",
    "## Prompt\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.prompts.prompt_type import PromptType\n",
    "from prompts import QUERY_GEN_PROMPT\n",
    "from prompts import DEFAULT_TEXT_QA_PROMPT_TMPL\n",
    "\n",
    "# Display\n",
    "from utils import pprint_response_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"google/gemma-7b-it\"\n",
    "# MODEL_NAME = \"TheBloke/SOLAR-10.7B-v1.0-GPTQ\"\n",
    "# MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "# MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# MODEL_NAME = \"Qwen/Qwen-14B-Chat-Int4\"\n",
    "\n",
    "# embed_name = \"BAAI/bge-small-en\"\n",
    "# embed_name = \"BAAI/bge-small-en-v1.5\" # 256 : 39s, 512 : 23.7s\n",
    "embed_name = \"thenlper/gte-base\" # 256 : 27.1s, 512 : 18.4s\n",
    "# embed_name = \"jamesgpt1/sf_model_e5\" # 256 : 41s, 512 : 18s\n",
    "\n",
    "# load local embedding model and llm model\n",
    "service_context, embed_model, llm = local_llm_model(MODEL_NAME,\n",
    "                                                    embed_name,\n",
    "                                                    type_='local',#,'openai',#'local',\n",
    "                                                    token_counter= False\n",
    "                                                    )\n",
    "set_global_service_context(service_context)\n",
    "\n",
    "# load vector db\n",
    "index, storage_context = load_db(embed_name, embed_size = 'h2') #h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "w_post_processor = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "d_post_processor = DuplecatedNodePostprocessor()\n",
    "u_post_processor = UnionNodePostprocessor()\n",
    "u_post_processor2 = UnionNodePostprocessorSortedScore()\n",
    "s_post_processor = SentenceTransformerRerank(\n",
    "        top_n =  40,\n",
    "        model = 'sentence-transformers/all-mpnet-base-v2' # avsolatorio/GIST-Embedding-v0\n",
    "        )\n",
    "\n",
    "l_post_processor = LongContextReorder()\n",
    "t_post_processor = LimitRetrievedNodesLength(limit=4000)\n",
    "from llama_index import ServiceContext  \n",
    "from llama_index.llms import OpenAI\n",
    "llm_post_processor = LLMRerank(\n",
    "        # choice_select_prompt = \n",
    "        service_context = ServiceContext.from_defaults(\n",
    "                llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\")),\n",
    "        top_n = 14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../questions/questions.json', 'r') as f:\n",
    "   questions = json.load(f)\n",
    "   \n",
    "# questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "# from prompts import DEFAULT_TREE_SUMMARIZE_TMPL\n",
    "\n",
    "\n",
    "DEFAULT_TEXT_QA_PROMPT_TMPL = \"\"\"\n",
    "\"Answer queries without using prior knowledge based on a given Context\"\n",
    "Context :\n",
    "{context_str}\n",
    "Query : {query_str}\n",
    "Answer : \n",
    "\"\"\"\n",
    "DEFAULT_TREE_SUMMARIZE_TMPL = (\n",
    "    \"The context below is the title of the article, and the answer to the query referencing that article.\"\n",
    "    \"Given the information from multiple sources and not prior knowledge, answer the query.\\n\"\n",
    "    \"When answering, be sure to include a ## separated title in your answer.\"\n",
    "    \n",
    "    \"Please answer in the format of python list.\\n\"\n",
    "    \"Returns the number preceding every title that can answer the query.\"\n",
    "    \"If no number is relevant, answer with an empty list [].\"\n",
    "    \n",
    "    'Example format: \\n'\n",
    "    \"----------------------\\n\"\n",
    "    \"## 0. Title : <Title 0>\\n\"\n",
    "    \"<Answer about query of <Title 0>\\n\"\n",
    "    \"## 1. Title : <Title 1>\\n\"\n",
    "    \"<Answer about query of <Title 1>\\n\"\n",
    "    \"...\\n\\n\"\n",
    "    \"## n. Title : <Title n>\\n\"\n",
    "    \"<Answer about query of <Title n>\\n\"\n",
    "    \n",
    "    \"If you choice the number 0 and 2, then answer is [0, 1], like below.\"\n",
    "    \"----------------------\\n\"\n",
    "    \"Query : <query>\\n\"\n",
    "    \"Answer : \\n\"\n",
    "    \"[0, 1]\"\n",
    "    \"\\n\\n\"\n",
    "    \n",
    "    \"If you choice the number just 0, then answer is [0], like below.\"\n",
    "    \"----------------------\\n\"\n",
    "    \"Query : <query>\\n\"\n",
    "    \"Answer : \\n\"\n",
    "    \"[0]\"\n",
    "    \"\\n\\n\"\n",
    "\n",
    "    \"Let's try this now: \\n\\n\"\n",
    "    \"----------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"----------------------\\n\"\n",
    "    \"Query : {query_str}\\n\"\n",
    "    \"Answer : \\n\"\n",
    ")\n",
    "FINAL_QA_PROMPT_TMPL = \"\"\"\n",
    "Base your answer on the context.\n",
    "If NO context is given, Don't use your prior knowledge and answer with something like \"no context was given\".\n",
    "Or, If the query is different from what you know or context, you can answer with \"Different answer based on my knowledge and context Because...\"\n",
    "Please provide a numbered response to the papers you found, as shown below.\n",
    "\n",
    "----------------------\n",
    "Context : \n",
    "<context>\n",
    "Query : \n",
    "<query>\n",
    "Answer : \n",
    "the first answer is ...\n",
    "\n",
    "the second answer is ...\n",
    "\n",
    "the third answer is ...\n",
    "----------------------\n",
    "\n",
    "\"Let's try this now:\"\n",
    "----------------------\n",
    "Context :\n",
    "{context_str}\n",
    "Query : {query_str}\n",
    "Answer : \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query engine\n",
    "from engine import query_engine, retriever_engine\n",
    "\n",
    "retriever = retriever_engine(top_k = 40, storage_context=storage_context, retrieve_mode='hierarchical', index=index)\n",
    "final_response, response, num_content_dict, nodes, = query_engine(\n",
    "    retriever,\n",
    "    query,\n",
    "    node_postprocessors = [d_post_processor, u_post_processor2, s_post_processor],\n",
    "    service_context = service_context,\n",
    "    DEFAULT_TEXT_QA_PROMPT_TMPL = DEFAULT_TEXT_QA_PROMPT_TMPL,\n",
    "    DEFAULT_TREE_SUMMARIZE_TMPL = DEFAULT_TREE_SUMMARIZE_TMPL,\n",
    "    FINAL_QA_PROMPT_TMPL = FINAL_QA_PROMPT_TMPL\n",
    "    )\n",
    "\n",
    "import textwrap\n",
    "from utils import sim_sentence_extract\n",
    "print(textwrap.fill(final_response, width=70))\n",
    "print()\n",
    "print('Sources : ')\n",
    "for idx, i in enumerate(eval(response)):\n",
    "    print(f\"{idx}. Title : {num_content_dict[i].metadata['file_name']}\")\n",
    "    pprint_res = sim_sentence_extract(query, num_content_dict[i], 350)\n",
    "    print(textwrap.fill(f\"Text : {pprint_res}\", width=70))\n",
    "    \n",
    "nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
